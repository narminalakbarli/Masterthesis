# Chapter 4 — Methodology

## Techniques and methods described

- **End-to-end framework**: data management → preprocessing → balancing → model training → thresholding → evaluation.
- **Baseline ML models**: LR, DT, RF, XGBoost, CatBoost.
- **Deep-learning models**: FFNN/LSTM/CNN/attention-style architectures.
- **Ensemble methods**: stacking and hybrid combinations.
- **Hyperparameter tuning strategy**: controlled model parameterization and selection.
- **Metrics**: recall, precision, F1/F2, AUC-ROC, AUC-PR.
- **Operational economics**: fraud-loss vs review-cost cost-benefit analysis.
- **Responsible AI themes**: fairness/transparency/explainability discussed conceptually.
- **Reproducibility**: config-driven execution and deterministic seeds.
- **Rule-based benchmark** included as reference system.

## Implementation check

- Implemented directly in pipeline:
  - preprocessing/balancing/training/thresholding/evaluation loop,
  - all metric families,
  - rule-based benchmark and relative savings,
  - config-driven reproducibility.
- **Gap addressed in this update**: explicit runnable studies for
  - model-family comparison,
  - ensemble-only comparison,
  - anomaly-only comparison.
- **Still conceptual/not fully implemented**: dedicated fairness metrics and SHAP/LIME explainability outputs are discussed in thesis framing but are not currently generated by the code.
