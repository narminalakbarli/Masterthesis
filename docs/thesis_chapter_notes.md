# Thesis chapter notes

- Total pages: 78

## Chapter 1 - Introduction
- Page range: 6-13

6 CHAPTER 1 - INTRODUCTION 1.1 Background and importance of payment cards Payment cards; credit, debit and prepaid -have become indispensable in modern commerce. They provide convenience to consumers and enable merchants to accept payment instantly with lower cash‑handling risks. Consequently, card transactions account for a large share of retail spending. Global card purchase volume (for goods, services and cash advances) grew to $51.92 trillion in 2024 [13], continuing a steady upward trajectory since the early 2010s. Even small changes in fraud rates can therefore translate into billions of dollars in absolute losses. The evolution of payment cards has transformed the financial landscape over the past several decades. What began as simple magnetic stripe cards in the 1970s has evolved into sophisticated payment ecosystems encompassing chip‑based cards, contactless payments, mobile wallets, and digital payment platforms. This transformation has been driven by technological advances, changing consumer preferences, and the need for faster, more secure transaction processing. The shift from cash to card‑based payments has been particularly pronounced in developed economies, where card transactions now represent in the majority of retail purchases. The post‑pandemic recovery accelerated the adoption of digital wallets and contactless payments. FICO notes that digital wallets now account for 53 % of global e‑commerce spending [15], reflecting consumers' shift to online shopping and mobile checkout. Similarly, real‑time payment systems (RTP) have gained traction, offering instant settlement between banks. This rapid digitization has fundamentally altered how consumers interact with payment systems, creating new opportunities for both legitimate commerce and fraudulent activity. While these innovations improve user experience, they also increase the attack surface: card data travels through more channels, is stored in more applications and can be compromised via phishing, malware or database breaches. In January 2024, the so‑called "mother of all breaches" exposed 26 billion user records from popular services, including login credentials that fraudsters could leverag...

## Chapter 2 - Literature Review
- Page range: 14-21

14 CHAPTER 2 - LITERATURE REVIEW 2.1 Overview and purpose The literature on payment‑card fraud detection spans decades and encompasses criminal typologies, data‑driven detection methodologies, statistical challenges and industry best practices. This chapter synthesises research across these areas to provide a foundation for the experimental work in Chapters 3–5. By reviewing fraud methods, rule‑based and machine‑learning (ML) detection systems, class‑imbalance mitigation, spatio‑temporal modelling and unsupervised approaches, we highlight strengths, limitations and open questions that motivate our integrated framework. The field of fraud detection has evolved significantly since the early days of simple rule‑based systems. Academic research has progressed from basic statistical models to sophisticated machine learning and deep learning architectures, while industry has developed proprietary systems that combine multiple detection strategies. However, a comprehensive synthesis that integrates spatial‑temporal features with class balancing techniques across the full spectrum of ML and DL models remains lacking. This literature review addresses this gap by examining both foundational research and recent advances, identifying where integration of different approaches can yield improved detection performance. Our review is structured to progress from general fraud context to specific technical approaches. We begin by examining fraud typologies and global trends, establishing the problem domain. We then review traditional detection methods, including rule‑based systems and classical statistical approaches, to understand the baseline against which modern methods are compared. Next, we survey supervised machine learning methods, class imbalance techniques, and deep learning architectures, highlighting both their individual contributions and potential for integration. Finally, we identify research gaps that motivate our comprehensive experimental framework. 2.2 Fraud methods and global trends Credit‑ and debit‑card fraud manifests in multiple forms. Card‑present fraud involves the physical card and includes lost/stolen cards, counterfeit cards and skimming. EMV chip tech...

## Chapter 3 - Research Questions And Data
- Page range: 22-31

22 CHAPTER 3 - RESEARCH QUESTIONS AND DATA 3.1 Research questions revisited This thesis seeks to assess whether combining spatial–temporal features with class‑balancing techniques can significantly improve credit‑card‑fraud detection. Drawing on the literature review, we refine and expand our research questions: RQ1 – Added value of spatial–temporal context: Does incorporating geolocation and temporal features improve the recall, precision and overall F1‑score of fraud‑detection models compared with models that use only basic transaction features? Earlier research suggests that fraudsters exhibit temporal aggregation (e.g., multiple transactions within minutes) and spatial aggregation (transactions at a small set of merchants far from the cardholder's residence). We hypothesise that explicitly capturing these patterns will allow models to discriminate between normal and fraudulent behaviours more effectively. RQ2 – Effectiveness of class‑balancing strategies: Which balancing technique—random oversampling, SMOTE, undersampling or hybrid methods—yields the best trade‑off between detecting fraud (recall) and minimising false positives (precision) when combined with spatial–temporal features? Class imbalance is extreme: in the widely used Kaggle credit‑card‑fraud dataset, only 0.172 % of transactions are fraudulent, and Sinčák's dataset is similarly skewed. [4] Oversampling, undersampling and SMOTE can rebalance the data, but each has limitations. We examine their effectiveness in our hybrid model context. RQ3 – Comparative performance of ML/DL models: How do traditional machine‑learning algorithms (logistic regression, random forests, gradient boosting) compare with deep‑learning architectures (feedforward neural networks, LSTMs) when trained on balanced datasets with spatial–temporal features? Previous studies indicate gradient boosting often outperforms other algorithms in fraud detection, but deep models may capture complex patterns when sufficient data and features are available. RQ4 – Benchmark against a rule‑based system: To what extent does our best-performing model outperform or complement a real bank's rule‑based system in terms of fraud capture rate, fals...

## Chapter 4 - Methodology
- Page range: 32-42

32 CHAPTER 4 - METHODOLOGY 4.1 Overview of the methodological framework To evaluate the effectiveness of combining spatial–temporal features with class‑balancing techniques, we design a comprehensive experimental pipeline. The methodology encompasses data preprocessing, model selection and training, hyper‑parameter tuning, evaluation metrics, cost–benefit analysis and fairness considerations. A key principle is rigorous experimental design: we avoid common pitfalls such as data leakage, improper temporal validation and metric manipulation, which can produce deceptively high performance. By adhering to sound practices, we ensure that our results reflect genuine improvements rather than artefacts of flawed evaluation. 4.2 Preprocessing and data management 4.2.1 Data cleaning and feature transformation As described in Chapter 3, our dataset combines the Kaggle credit‑card‑fraud transactions (284 807 rows, 492 frauds) with variables from Sinčák's synthetic dataset and newly engineered spatial–temporal features. [4] We standardise continuous features (`Amount`, `distance`, rolling statistics) using z‑scores and retain the original values for cost‑sensitive analysis. Categorical variables (e.g., `channel`, `transaction_type`, `region`) are one‑hot encoded. For temporal variables, we transform `Time` (seconds since the first transaction) into `hour_of_day`, `day_of_week`, `is_weekend`, `season` and inter‑transaction times. The geolocation features include the haversine distance to the cardholder's residence and region clusters. 4.2.2 Avoiding data leakage Data leakage occurs when information from the test set inadvertently influences the training process, leading to inflated performance. Liu et al. (2025) [6] highlight that many fraud‑detection studies suffer from data leakage from improper preprocessing sequences, such as applying SMOTE before splitting the data. This contaminates the test set with synthetic fraud samples derived from training data, artificially boosting recall. To prevent leakage: Temporal order and stratification: We sort transactions chronologically by `Time` and ensure that each cardholder's transactions reside in a single split. This respects the...

## Chapter 5 - Results And Discussion
- Page range: 43-56

43 CHAPTER 5 - RESULTS AND DISCUSSION 5.1 Impact of spatial–temporal features The first research question asked whether adding geolocation and temporal context improves fraud‑detection performance. To answer this, we trained baseline models on the Kaggle PCA features (`V1`–`V28`), `Time` and `Amount`, then retrained the same models on the augmented dataset that included channel, same‑state indicators, regional clusters, haversine distance to the cardholder's residence, and temporal metrics (e.g., hour of day, time since last transaction, day of week, inter‑transaction intervals). [4] This systematic comparison allows us to isolate the contribution of spatial–temporal features while controlling for other factors. We maintained identical model architectures, hyper‑parameters, and training procedures across both feature sets, ensuring that any performance differences can be attributed to the additional features rather than other experimental variations. Across all algorithms, the addition of spatial–temporal features improved recall and F1‑score. For example, a random forest (RF) model trained on the basic features achieved a recall of roughly 0.93, but when spatial–temporal features and SMOTE balancing were applied, recall increased to 0.96 with only a modest decline in precision (from 0.98 to 0.97). This represents a 3.2 percentage point improvement in recall, which translates to detecting approximately 15 additional fraud cases per 1,000 transactions—a significant improvement given the low base rate of fraud. Similar improvements were observed across other model types. Logistic regression showed a recall improvement from 0.60 to 0.68 when spatial–temporal features were added, though it still underperformed compared to tree‑based models. XGBoost improved from 0.78 to 0.82 recall, while CatBoost showed the largest absolute improvement, increasing from 0.77 to 0.85 recall. These consistent improvements across diverse model architectures suggest that spatial–temporal features capture fundamental patterns in fraud behavior that are not well represented by transaction‑level features alone. Feature‑importance analysis using permutation importance and SHAP values showed...

## Chapter 6 - Benchmark Against Rule
- Page range: 57-61

57 CHAPTER 6 - BENCHMARK AGAINST RULE-BASED SYSTEM 6.1 Introduction and motivation Financial institutions have historically relied on rule‑based systems to detect card fraud. Such systems codify expert knowledge into if‑then rules that flag suspicious transactions, e.g., "block any purchase over €1 000 made overseas at night." They are simple to implement and interpret but struggle to adapt to new fraud patterns. Despite the rise of machine learning, many banks continue to use rule‑based systems as their primary or secondary fraud detection mechanism, making it crucial to understand how modern ML/DL approaches compare. Recent research notes that rule‑based algorithms lack flexibility, leading to delayed detection and greater financial losses. For instance, an AI‑based fraud‑detection study compared machine‑learning (ML) methods to a rule‑based baseline and concluded that the latter failed to identify many subtle fraud cases. Moreover, simple tree‑like classifiers (resembling rule engines) achieved only about 75 % precision and recall, leaving a high number of false negatives. These observations underscore the need to evaluate how our hybrid ML/DL models measure up against an operational rule‑based system. This benchmarking is particularly important because rule‑based systems remain widely deployed in the industry. Understanding their strengths and limitations relative to ML/DL approaches enables informed decisions about system upgrades and helps identify scenarios where hybrid approaches may be optimal. Additionally, comparing against rule‑based systems provides a practical baseline that practitioners can relate to, making research findings more actionable. 6.2 Description of the benchmark rule‑based system We implement a simplified rule‑based system inspired by the Czech bank's fraud‑detection engine described in Sinčák's thesis [2]. This system uses thresholds on transaction amount, velocity, merchant category, channel and geographic distance. Key rules include: High‑value foreign transactions: Decline any transaction over €1 000 conducted outside the cardholder's home country or region, unless similar transactions have been approved before. Rapid‑fire transac...

## Chapter 7 - Conclusion And Future Work
- Page range: 62-78

62 CHAPTER 7 - CONCLUSION AND FUTURE WORK 7.1 Summary of contributions This thesis set out to investigate whether integrating spatial–temporal context with class‑balancing techniques improves credit‑card‑fraud detection. We began by contextualising the scale of card payments and fraud, noting that global card purchase volume exceeded $51.92 trillion in 2024, while fraud losses climbed to $33.83 billion in 2023. Recognising that fraud constitutes a tiny fraction of transactions yet causes disproportionate losses, we identified limitations of traditional rule‑based systems and the challenge of extreme class imbalance. Our research addressed a critical gap in the literature: while spatial–temporal features and class balancing have been studied individually, their integration across a comprehensive range of ML and DL models had not been systematically evaluated. By combining insights from Lestari's (2024) work on spatial–temporal features and Sinčák's (2023) benchmarking against real systems, we created a unified framework that provides actionable guidance for practitioners. Our principal contributions can be summarised as follows: Dataset augmentation: We constructed a hybrid dataset by combining the Kaggle credit‑card‑fraud data [4] (284 807 transactions, 492 frauds) with synthetic variables from Sinčák's thesis [2] (channel, same state, merchant category distribution) and engineered spatial–temporal features inspired by Lestari's work [3]. We introduced features such as haversine distance to the cardholder's residence, regional clusters, hour of day, inter‑transaction time and region change. This enriched dataset enabled us to examine the joint impact of spatial and temporal patterns on fraud detection, providing a testbed that reflects real‑world complexities while preserving privacy through synthetic data. [4] Balancing strategies: We evaluated several class‑imbalance mitigation techniques—random oversampling, SMOTE [7], SMOTE variants, random undersampling, hybrid SMOTE– GAN methods [8] and cost‑sensitive learning [10]—across multiple model types. Our systematic evaluation revealed that SMOTE [7] consistently produced the best performance, achieving optimal ba...
